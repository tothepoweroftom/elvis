{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #Opencv\n",
    "import cv#Opencv\n",
    "import numpy as np\n",
    "\n",
    "import Image #Image from PIL\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DetectFace(image, faceCascade, returnImage=False):\n",
    "    # This function takes a grey scale cv image and finds\n",
    "    # the patterns defined in the haarcascade function\n",
    "    # modified from: http://www.lucaamore.com/?p=638\n",
    "\n",
    "    #variables    \n",
    "    min_size = (20,20)\n",
    "    haar_scale = 1.1\n",
    "    min_neighbors = 3\n",
    "    haar_flags = 0\n",
    "\n",
    "    # Equalize the histogram\n",
    "    cv.EqualizeHist(image, image)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = cv.HaarDetectObjects(\n",
    "            image, faceCascade, cv.CreateMemStorage(0),\n",
    "            haar_scale, min_neighbors, haar_flags, min_size\n",
    "        )\n",
    "\n",
    "    # If faces are found\n",
    "    if faces and returnImage:\n",
    "        for ((x, y, w, h), n) in faces:\n",
    "            # Convert bounding box to two CvPoints\n",
    "            pt1 = (int(x), int(y))\n",
    "            pt2 = (int(x + w), int(y + h))\n",
    "            cv.Rectangle(image, pt1, pt2, cv.RGB(255, 0, 0), 5, 8, 0)\n",
    "\n",
    "    if returnImage:\n",
    "        return image\n",
    "    else:\n",
    "        return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pil2cvGrey(pil_im):\n",
    "    # Convert a PIL image to a greyscale cv image\n",
    "    # from: http://pythonpath.wordpress.com/2012/05/08/pil-to-opencv-image/\n",
    "    pil_im = pil_im.convert('L')\n",
    "    cv_im = cv.CreateImageHeader(pil_im.size, cv.IPL_DEPTH_8U, 1)\n",
    "    cv.SetData(cv_im, pil_im.tostring(), pil_im.size[0]  )\n",
    "    return cv_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv2pil(cv_im):\n",
    "    # Convert the cv image to a PIL image\n",
    "    return Image.fromstring(\"L\", cv.GetSize(cv_im), cv_im.tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgCrop(image, cropBox, boxScale=1):\n",
    "    # Crop a PIL image with the provided box [x(left), y(upper), w(width), h(height)]\n",
    "\n",
    "    # Calculate scale factors\n",
    "    xDelta=max(cropBox[2]*(boxScale-1),0)\n",
    "    yDelta=max(cropBox[3]*(boxScale-1),0)\n",
    "\n",
    "    # Convert cv box to PIL box [left, upper, right, lower]\n",
    "    PIL_box=[cropBox[0]-xDelta, cropBox[1]-yDelta, cropBox[0]+cropBox[2]+xDelta, cropBox[1]+cropBox[3]+yDelta]\n",
    "\n",
    "    return image.crop(PIL_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def faceCrop(imagePattern,boxScale=1):\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    imgList=glob.glob(imagePattern)\n",
    "    if len(imgList)<=0:\n",
    "        print 'No Images Found'\n",
    "        return\n",
    "\n",
    "    for img in imgList:\n",
    "        pil_im=Image.open(img)\n",
    "        cv_im=pil2cvGrey(pil_im)\n",
    "        faces=DetectFace(cv_im,faceCascade)\n",
    "        if faces:\n",
    "            n=1\n",
    "            for face in faces:\n",
    "                croppedImage=imgCrop(pil_im, face[0],boxScale=boxScale)\n",
    "                fname,ext=os.path.splitext(img)\n",
    "                imgs.append(croppedImage)\n",
    "                croppedImage.save('crop'+str(n)+ext)\n",
    "                n+=1\n",
    "        else:\n",
    "            print 'No faces found:', img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(imageFilePath):\n",
    "    pil_im=Image.open(imageFilePath)\n",
    "    cv_im=pil2cvGrey(pil_im)\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "    face_im=DetectFace(cv_im,faceCascade, returnImage=True)\n",
    "    img=cv2pil(face_im)\n",
    "    img.show()\n",
    "    img.save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceCrop('Elvis_Presley_Jailhouse_Rock2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image._ImageCrop image mode=RGB size=26x26 at 0x10FD9C710>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background = Image.open('Wind-turbines.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore = Image.open('crop1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "background.paste(fore, (123, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "background.save('output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-341ef8ee2c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tom.power/anaconda/envs/magenta/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mpaste\u001b[0;34m(self, im, box, mask)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "# Read image\n",
    "im = cv2.imread(\"Wind-turbines.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "# Set up the detector with default parameters.\n",
    "detector = cv2.SimpleBlobDetector()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    " \n",
    "# Show keypoints\n",
    "x = keypoints[0].pt[0]\n",
    "y = keypoints[0].pt[1]\n",
    "\n",
    "background.paste(fore, (int(x),int(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

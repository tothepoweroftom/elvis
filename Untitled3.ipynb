{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #Opencv\n",
    "import cv#Opencv\n",
    "import numpy as np\n",
    "\n",
    "import Image #Image from PIL\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DetectFace(image, faceCascade, returnImage=False):\n",
    "    # This function takes a grey scale cv image and finds\n",
    "    # the patterns defined in the haarcascade function\n",
    "    # modified from: http://www.lucaamore.com/?p=638\n",
    "\n",
    "    #variables    \n",
    "    min_size = (20,20)\n",
    "    haar_scale = 1.1\n",
    "    min_neighbors = 3\n",
    "    haar_flags = 0\n",
    "\n",
    "    # Equalize the histogram\n",
    "    cv.EqualizeHist(image, image)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = cv.HaarDetectObjects(\n",
    "            image, faceCascade, cv.CreateMemStorage(0),\n",
    "            haar_scale, min_neighbors, haar_flags, min_size\n",
    "        )\n",
    "\n",
    "    # If faces are found\n",
    "    if faces and returnImage:\n",
    "        for ((x, y, w, h), n) in faces:\n",
    "            # Convert bounding box to two CvPoints\n",
    "            pt1 = (int(x), int(y))\n",
    "            pt2 = (int(x + w), int(y + h))\n",
    "            cv.Rectangle(image, pt1, pt2, cv.RGB(255, 0, 0), 5, 8, 0)\n",
    "\n",
    "    if returnImage:\n",
    "        return image\n",
    "    else:\n",
    "        return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pil2cvGrey(pil_im):\n",
    "    # Convert a PIL image to a greyscale cv image\n",
    "    # from: http://pythonpath.wordpress.com/2012/05/08/pil-to-opencv-image/\n",
    "    pil_im = pil_im.convert('L')\n",
    "    cv_im = cv.CreateImageHeader(pil_im.size, cv.IPL_DEPTH_8U, 1)\n",
    "    cv.SetData(cv_im, pil_im.tostring(), pil_im.size[0]  )\n",
    "    return cv_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv2pil(cv_im):\n",
    "    # Convert the cv image to a PIL image\n",
    "    return Image.fromstring(\"L\", cv.GetSize(cv_im), cv_im.tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgCrop(image, cropBox, boxScale=1):\n",
    "    # Crop a PIL image with the provided box [x(left), y(upper), w(width), h(height)]\n",
    "\n",
    "    # Calculate scale factors\n",
    "    xDelta=max(cropBox[2]*(boxScale-1),0)\n",
    "    yDelta=max(cropBox[3]*(boxScale-1),0)\n",
    "\n",
    "    # Convert cv box to PIL box [left, upper, right, lower]\n",
    "    PIL_box=[cropBox[0]-xDelta, cropBox[1]-yDelta, cropBox[0]+cropBox[2]+xDelta, cropBox[1]+cropBox[3]+yDelta]\n",
    "\n",
    "    return image.crop(PIL_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def faceCrop(imagePattern,boxScale=1):\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    imgList=glob.glob(imagePattern)\n",
    "    if len(imgList)<=0:\n",
    "        print 'No Images Found'\n",
    "        return\n",
    "\n",
    "    for img in imgList:\n",
    "        pil_im=Image.open(img)\n",
    "        cv_im=pil2cvGrey(pil_im)\n",
    "        faces=DetectFace(cv_im,faceCascade)\n",
    "        if faces:\n",
    "            n=1\n",
    "            for face in faces:\n",
    "                croppedImage=imgCrop(pil_im, face[0],boxScale=boxScale)\n",
    "                fname,ext=os.path.splitext(img)\n",
    "                croppedImage.save('crop'+str(n)+ext)\n",
    "                imgs.append('crop'+str(n)+ext)\n",
    "\n",
    "\n",
    "                n+=1\n",
    "        else:\n",
    "            print 'No faces found:', img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(imageFilePath):\n",
    "    pil_im=Image.open(imageFilePath)\n",
    "    cv_im=pil2cvGrey(pil_im)\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "    face_im=DetectFace(cv_im,faceCascade, returnImage=True)\n",
    "    img=cv2pil(face_im)\n",
    "    img.show()\n",
    "    img.save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCrop('elvis-presley-army-xlarge.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image._ImageCrop image mode=RGB size=190x190 at 0x10FD840E0>,\n",
       " 'elvis-presley-army-xlarge.jpg',\n",
       " 'crop1.jpg']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background = Image.open('wind-turbines-2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore = Image.open('crop1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "background.paste(fore, (123, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    " \n",
    "# Change thresholds\n",
    "params.minThreshold = 10;\n",
    "params.maxThreshold = 500;\n",
    " \n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 140\n",
    " \n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.1\n",
    " \n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    " \n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    " \n",
    "# Create a detector with the parameters\n",
    "ver = (cv2.__version__).split('.')\n",
    "if int(ver[0]) < 3 :\n",
    "    detector = cv2.SimpleBlobDetector(params)\n",
    "else : \n",
    "    detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "im = cv2.imread(\"wind-turbines-2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "# Set up the detector with default parameters.\n",
    "detector = cv2.SimpleBlobDetector()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "\n",
    "for key in keypoints:\n",
    "    # Show keypoints\n",
    "    x = key.pt[0]\n",
    "    y = key.pt[1]\n",
    "\n",
    "    background.paste(fore, (int(x),int(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background.save('output3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
